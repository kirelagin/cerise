
@article{crse21,
	title = {Coupled Relational Symbolic Execution for Differential Privacy},
	url = {http://arxiv.org/abs/2007.12987},
	abstract = {Differential privacy is a de facto standard in data privacy with applications in the private and public sectors. Most of the techniques that achieve differential privacy are based on a judicious use of randomness. However, reasoning about randomized programs is difficult and error prone. For this reason, several techniques have been recently proposed to support designer in proving programs differentially private or in finding violations to it. In this work we propose a technique based on symbolic execution for reasoning about differential privacy. Symbolic execution is a classic technique used for testing, counterexample generation and to prove absence of bugs. Here we use symbolic execution to support these tasks specifically for differential privacy. To achieve this goal, we leverage two ideas that have been already proven useful in formal reasoning about differential privacy: relational reasoning and probabilistic coupling. Our technique integrates these two ideas and shows how such a combination can be used to both verify and find violations to differential privacy.},
	journaltitle = {{arXiv}:2007.12987 [cs]},
	author = {Farina, Gian Pietro and Chong, Stephen and Gaboardi, Marco},
	urldate = {2021-03-06},
	date = {2020-07-25},
	eprinttype = {arxiv},
	eprint = {2007.12987},
	keywords = {Computer Science - Logic in Computer Science, Computer Science - Programming Languages, dp},
	file = {arXiv Fulltext PDF:/home/kirelagin/Zotero/storage/IF4N7BJN/Farina et al. - 2020 - Coupled Relational Symbolic Execution for Differen.pdf:application/pdf;arXiv.org Snapshot:/home/kirelagin/Zotero/storage/8CQHDCDS/2007.html:text/html}
}

@inproceedings{rse19,
	location = {New York, {NY}, {USA}},
	title = {Relational Symbolic Execution},
	isbn = {978-1-4503-7249-7},
	url = {https://doi.org/10.1145/3354166.3354175},
	doi = {10.1145/3354166.3354175},
	series = {{PPDP} '19},
	abstract = {Symbolic execution is a classical program analysis technique used to show that programs satisfy or violate given specifications. In this work we generalize symbolic execution to support program analysis for relational specifications in the form of relational properties - these are properties about two runs of two programs on related inputs, or about two executions of a single program on related inputs. Relational properties are useful to formalize notions in security and privacy, and to reason about program optimizations. We design a relational symbolic execution engine, named {RelSym} which supports interactive refutation, as well as proving of relational properties for programs written in a language with arrays and for-like loops.},
	booktitle = {Proceedings of the 21st International Symposium on Principles and Practice of Declarative Programming},
	publisher = {Association for Computing Machinery},
	author = {Farina, Gian Pietro and Chong, Stephen and Gaboardi, Marco},
	date = {2019},
	note = {event-place: Porto, Portugal},
	keywords = {dp}
}

@inproceedings{prr12,
	location = {New York, {NY}, {USA}},
	title = {Probabilistic relational reasoning for differential privacy},
	isbn = {978-1-4503-1083-3},
	url = {https://doi.org/10.1145/2103656.2103670},
	doi = {10.1145/2103656.2103670},
	series = {{POPL} '12},
	abstract = {Differential privacy is a notion of confidentiality that protects the privacy of individuals while allowing useful computations on their private data. Deriving differential privacy guarantees for real programs is a difficult and error-prone task that calls for principled approaches and tool support. Approaches based on linear types and static analysis have recently emerged; however, an increasing number of programs achieve privacy using techniques that cannot be analyzed by these approaches. Examples include programs that aim for weaker, approximate differential privacy guarantees, programs that use the Exponential mechanism, and randomized programs that achieve differential privacy without using any standard mechanism. Providing support for reasoning about the privacy of such programs has been an open problem. We report on {CertiPriv}, a machine-checked framework for reasoning about differential privacy built on top of the Coq proof assistant. The central component of {CertiPriv} is a quantitative extension of a probabilistic relational Hoare logic that enables one to derive differential privacy guarantees for programs from first principles. We demonstrate the expressiveness of {CertiPriv} using a number of examples whose formal analysis is out of the reach of previous techniques. In particular, we provide the first machine-checked proofs of correctness of the Laplacian and Exponential mechanisms and of the privacy of randomized and streaming algorithms from the recent literature.},
	pages = {97--110},
	booktitle = {Proceedings of the 39th annual {ACM} {SIGPLAN}-{SIGACT} symposium on Principles of programming languages},
	publisher = {Association for Computing Machinery},
	author = {Barthe, Gilles and Köpf, Boris and Olmedo, Federico and Zanella Béguelin, Santiago},
	urldate = {2021-03-05},
	date = {2012-01-25},
	keywords = {coq proof assistant, differential privacy, dp, relational hoare logic},
	file = {Submitted Version:/home/kirelagin/Zotero/storage/9EGTKTJL/Barthe et al. - 2012 - Probabilistic relational reasoning for differentia.pdf:application/pdf}
}

@inproceedings{approx16,
	location = {New York, {NY}, {USA}},
	title = {Proving Differential Privacy via Probabilistic Couplings},
	isbn = {978-1-4503-4391-6},
	url = {https://doi.org/10.1145/2933575.2934554},
	doi = {10.1145/2933575.2934554},
	series = {{LICS} '16},
	abstract = {Over the last decade, differential privacy has achieved widespread adoption within the privacy community. Moreover, it has attracted significant attention from the verification community, resulting in several successful tools for formally proving differential privacy. Although their technical approaches vary greatly, all existing tools rely on reasoning principles derived from the composition theorem of differential privacy. While this suffices to verify most common private algorithms, there are several important algorithms whose privacy analysis does not rely solely on the composition theorem. Their proofs are significantly more complex, and are currently beyond the reach of verification tools. In this paper, we develop compositional methods for formally verifying differential privacy for algorithms whose analysis goes beyond the composition theorem. Our methods are based on deep connections between differential privacy and probabilistic couplings, an established mathematical tool for reasoning about stochastic processes. Even when the composition theorem is not helpful, we can often prove privacy by a coupling argument. We demonstrate our methods on two algorithms: the Exponential mechanism and the Above Threshold algorithm, the critical component of the famous Sparse Vector algorithm. We verify these examples in a relational program logic {apRHL}+, which can construct approximate couplings. This logic extends the existing {apRHL} logic with more general rules for the Laplace mechanism and the one-sided Laplace mechanism, and new structural rules enabling pointwise reasoning about privacy; all the rules are inspired by the connection with coupling. While our paper is presented from a formal verification perspective, we believe that its main insight is of independent interest for the differential privacy community.},
	pages = {749--758},
	booktitle = {Proceedings of the 31st Annual {ACM}/{IEEE} Symposium on Logic in Computer Science},
	publisher = {Association for Computing Machinery},
	author = {Barthe, Gilles and Gaboardi, Marco and Grégoire, Benjamin and Hsu, Justin and Strub, Pierre-Yves},
	urldate = {2021-03-05},
	date = {2016-07-05},
	keywords = {dp},
	file = {Full Text PDF:/home/kirelagin/Zotero/storage/UI3ZZM23/Barthe et al. - 2016 - Proving Differential Privacy via Probabilistic Cou.pdf:application/pdf}
}

@book{lindvall92,
	title = {Lectures on the Coupling Method},
	isbn = {978-0-471-54025-0},
	url = {https://books.google.com/books?id=ffWiQgAACAAJ},
	series = {Wiley Series in Probability and Statistics - Applied Probability and Statistics Section},
	publisher = {Wiley},
	author = {Lindvall, T.},
	date = {1992},
	lccn = {92012811},
	keywords = {dp, probability}
}

@article{coupling17,
	title = {Synthesizing coupling proofs of differential privacy},
	volume = {2},
	url = {https://doi.org/10.1145/3158146},
	doi = {10.1145/3158146},
	abstract = {Differential privacy has emerged as a promising probabilistic formulation of privacy, generating intense interest within academia and industry. We present a push-button, automated technique for verifying ε-differential privacy of sophisticated randomized algorithms. We make several conceptual, algorithmic, and practical contributions: (i) Inspired by the recent advances on approximate couplings and randomness alignment, we present a new proof technique called coupling strategies, which casts differential privacy proofs as a winning strategy in a game where we have finite privacy resources to expend. (ii) To discover a winning strategy, we present a constraint-based formulation of the problem as a set of Horn modulo couplings ({HMC}) constraints, a novel combination of first-order Horn clauses and probabilistic constraints. (iii) We present a technique for solving {HMC} constraints by transforming probabilistic constraints into logical constraints with uninterpreted functions. (iv) Finally, we implement our technique in the {FairSquare} verifier and provide the first automated privacy proofs for a number of challenging algorithms from the differential privacy literature, including Report Noisy Max, the Exponential Mechanism, and the Sparse Vector Mechanism.},
	pages = {58:1--58:30},
	issue = {{POPL}},
	journaltitle = {Proceedings of the {ACM} on Programming Languages},
	shortjournal = {Proc. {ACM} Program. Lang.},
	author = {Albarghouthi, Aws and Hsu, Justin},
	urldate = {2021-03-06},
	date = {2017-12-27},
	keywords = {Differential Privacy, dp, Synthesis},
	file = {Full Text PDF:/home/kirelagin/Zotero/storage/2LMML9XU/Albarghouthi and Hsu - 2017 - Synthesizing coupling proofs of differential priva.pdf:application/pdf}
}

@article{symbolic,
	title = {Symbolic execution and program testing},
	volume = {19},
	issn = {0001-0782},
	url = {https://doi.org/10.1145/360248.360252},
	doi = {10.1145/360248.360252},
	abstract = {This paper describes the symbolic execution of programs. Instead of supplying the normal inputs to a program (e.g. numbers) one supplies symbols representing arbitrary values. The execution proceeds as in a normal execution except that values may be symbolic formulas over the input symbols. The difficult, yet interesting issues arise during the symbolic execution of conditional branch type statements. A particular system called {EFFIGY} which provides symbolic execution for program testing and debugging is also described. It interpretively executes programs written in a simple {PL}/I style programming language. It includes many standard debugging features, the ability to manage and to prove things about symbolic expressions, a simple program testing manager, and a program verifier. A brief discussion of the relationship between symbolic execution and program proving is also included.},
	pages = {385--394},
	number = {7},
	journaltitle = {Communications of the {ACM}},
	shortjournal = {Commun. {ACM}},
	author = {King, James C.},
	urldate = {2021-03-06},
	date = {1976-07-01},
	keywords = {program debugging, program proving, program testing, program verification, symbolic execution, symbolic interpretation, testing}
}

@article{sparsevec,
	title = {Understanding the sparse vector technique for differential privacy},
	volume = {10},
	issn = {2150-8097},
	url = {https://doi.org/10.14778/3055330.3055331},
	doi = {10.14778/3055330.3055331},
	abstract = {The Sparse Vector Technique ({SVT}) is a fundamental technique for satisfying differential privacy and has the unique quality that one can output some query answers without apparently paying any privacy cost. {SVT} has been used in both the interactive setting, where one tries to answer a sequence of queries that are not known ahead of the time, and in the non-interactive setting, where all queries are known. Because of the potential savings on privacy budget, many variants for {SVT} have been proposed and employed in privacy-preserving data mining and publishing. However, most variants of {SVT} are actually not private. In this paper, we analyze these errors and identify the misunderstandings that likely contribute to them. We also propose a new version of {SVT} that provides better utility, and introduce an effective technique to improve the performance of {SVT}. These enhancements can be applied to improve utility in the interactive setting. Through both analytical and experimental comparisons, we show that, in the non-interactive setting (but not the interactive setting), the {SVT} technique is unnecessary, as it can be replaced by the Exponential Mechanism ({EM}) with better accuracy.},
	pages = {637--648},
	number = {6},
	journaltitle = {Proceedings of the {VLDB} Endowment},
	shortjournal = {Proc. {VLDB} Endow.},
	author = {Lyu, Min and Su, Dong and Li, Ninghui},
	urldate = {2021-03-06},
	date = {2017-02-01},
	keywords = {dp},
	file = {Submitted Version:/home/kirelagin/Zotero/storage/N4QQT8KJ/Lyu et al. - 2017 - Understanding the sparse vector technique for diff.pdf:application/pdf}
}